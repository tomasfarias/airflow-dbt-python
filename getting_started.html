<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Getting started &mdash; airflow-dbt-python 1.0.4 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/hack-font/3.3.0/web/hack.min.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Example DAGs" href="example_dags.html" />
    <link rel="prev" title="Introduction" href="introduction.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            airflow-dbt-python
          </a>
              <div class="version">
                1.0.4
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Getting started</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#requirements">Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="#installation">Installation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#from-pypi">From PyPI</a></li>
<li class="toctree-l3"><a class="reference internal" href="#building-from-source">Building from source</a></li>
<li class="toctree-l3"><a class="reference internal" href="#installing-in-mwaa">Installing in MWAA</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#accessing-a-dbt-project">Accessing a <em>dbt</em> project</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#single-machine-installation">Single-machine installation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#multi-machine-cloud-installation">Multi-machine/cloud installation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="example_dags.html">Example DAGs</a></li>
<li class="toctree-l1"><a class="reference internal" href="how_does_it_work.html">How does it work?</a></li>
<li class="toctree-l1"><a class="reference internal" href="development.html">Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="reference.html">Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">airflow-dbt-python</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Getting started</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/getting_started.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="getting-started">
<h1>Getting started<a class="headerlink" href="#getting-started" title="Permalink to this heading"></a></h1>
<p>This section guides you on installing <em>airflow-dbt-python</em> and getting your first <em>dbt</em> workflow DAG running.</p>
<section id="requirements">
<span id="id1"></span><h2>Requirements<a class="headerlink" href="#requirements" title="Permalink to this heading"></a></h2>
<p>Before using <em>airflow-dbt-python</em>, ensure you meet the following requirements:
* A <em>dbt</em> project using <a class="reference external" href="https://pypi.org/project/dbt-core/">dbt-core</a> version 1.0.0 or later.
* An Airflow environment using version 2.2 or later.</p>
<blockquote>
<div><ul class="simple">
<li><p>If using any managed service, like AWS MWAA, ensure your environment is created with a supported version of Airflow.</p></li>
<li><p>If self-hosting, Airflow installation instructions can be found in their <a class="reference external" href="https://airflow.apache.org/docs/apache-airflow/stable/installation/index.html">official documentation</a>.</p></li>
</ul>
</div></blockquote>
<ul class="simple">
<li><p>Running Python 3.7 or later in your Airflow environment.</p></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Even though we don’t impose any upper limits on versions of Airflow and <em>dbt</em>, it’s possible that new versions are not supported immediately after release, particularly for <em>dbt</em>. We recommend testing the latest versions before upgrading and <a class="reference external" href="https://github.com/tomasfarias/airflow-dbt-python/issues/new/choose">reporting any issues</a>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Older versions of Airflow and <em>dbt</em> may work with <em>airflow-dbt-python</em>, although we cannot guarantee this. Our testing pipeline runs the latest <em>dbt-core</em> with the latest Airflow release, and the latest version supported by <a class="reference external" href="https://aws.amazon.com/managed-workflows-for-apache-airflow/">AWS MWAA</a>.</p>
</div>
</section>
<section id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this heading"></a></h2>
<p>Your installation will vary according to your specific Airflow environment setup. These instructions cover a general approach by installing from PyPI or the GitHub repository, and how to install it in AWS MWAA. Other serviced offerings may require different steps, check the documentation of your managed service.</p>
<section id="from-pypi">
<h3>From PyPI<a class="headerlink" href="#from-pypi" title="Permalink to this heading"></a></h3>
<p><em>airflow-dbt-python</em> is available in <a class="reference external" href="https://pypi.org/project/airflow-dbt-python/">PyPI</a> and can be installed with <em>pip</em>:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>airflow-dbt-python
</pre></div>
</div>
<p>As a convenience, some <em>dbt</em> adapters can be installed by specifying extras. For example, if requiring the <em>dbt-redshift</em> adapter:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>airflow-dbt-python<span class="o">[</span>redshift<span class="o">]</span>
</pre></div>
</div>
<p>Or <em>dbt-snowflake</em>:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>airflow-dbt-python<span class="o">[</span>snowflake<span class="o">]</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>These <em>dbt</em> adapter extras are provided as a convenience. Any required <em>dbt</em> adapters can also be installed separatedly. Refer to the <a class="reference external" href="https://docs.getdbt.com/docs/supported-data-platforms">dbt documentation</a> for a list of supported adapters and how to install them.</p>
</div>
</section>
<section id="building-from-source">
<h3>Building from source<a class="headerlink" href="#building-from-source" title="Permalink to this heading"></a></h3>
<p><em>airflow-dbt-python</em> can also be built from source by cloning the GitHub repository:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/tomasfarias/airflow-dbt-python.git
<span class="nb">cd</span><span class="w"> </span>airflow-dbt-python
</pre></div>
</div>
<p>And installing with <em>Poetry</em>:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>poetry<span class="w"> </span>install
</pre></div>
</div>
<p>Any extra <em>dbt</em> adapters can be installed by specifying extras:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>poetry<span class="w"> </span>install<span class="w"> </span>-E<span class="w"> </span>postgres<span class="w"> </span>-E<span class="w"> </span>redshift<span class="w"> </span>-E<span class="w"> </span>bigquery<span class="w"> </span>-E<span class="w"> </span>snowflake
poetry<span class="w"> </span>install<span class="w"> </span>-E<span class="w"> </span>all
</pre></div>
</div>
</section>
<section id="installing-in-mwaa">
<h3>Installing in MWAA<a class="headerlink" href="#installing-in-mwaa" title="Permalink to this heading"></a></h3>
<p><em>airflow-dbt-python</em> can be installed in an Airflow environment managed by AWS via their <a class="reference external" href="https://aws.amazon.com/managed-workflows-for-apache-airflow/">Managed Workflows for Apache Airflow</a> service.</p>
<p>To do so, include <em>airflow-dbt-python</em> in the <em>requirements.txt</em> file provided to MWAA, for example:</p>
<div class="literal-block-wrapper docutils container" id="id2">
<div class="code-block-caption"><span class="caption-text">requirements.txt</span><a class="headerlink" href="#id2" title="Permalink to this code"></a></div>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>airflow-dbt-python<span class="o">[</span>redshift,s3<span class="o">]</span>
</pre></div>
</div>
</div>
<p>Installs <em>airflow-dbt-python</em>, <em>dbt-redshift</em> adapter, and all required libraries to support <em>dbt</em> S3 remotes.</p>
<p>Alternatively, <em>airflow-dbt-python</em> can also be provided to AWS MWAA via a <em>plugins.zip</em> file. This can be achieved by adding an <em>airflow-dbt-python</em> wheel to your <em>plugins.zip</em></p>
<p>For example, we can start by cloning the GitHub repository:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/tomasfarias/airflow-dbt-python.git
<span class="nb">cd</span><span class="w"> </span>airflow-dbt-python
</pre></div>
</div>
<p>Then building an <em>airflow-dbt-python</em> wheel using <em>poetry</em>:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>poetry<span class="w"> </span>build<span class="w"> </span>-f<span class="w"> </span>wheel
</pre></div>
</div>
<p>The wheel file can now be added to your <em>plugins.zip</em>, and the requirements can be updated to point to this wheel file:</p>
<div class="literal-block-wrapper docutils container" id="id3">
<div class="code-block-caption"><span class="caption-text">requirements.txt</span><a class="headerlink" href="#id3" title="Permalink to this code"></a></div>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>/usr/local/airflow/plugins/airflow_dbt_python-1.0.0-py3-none-any.whl
</pre></div>
</div>
</div>
</section>
</section>
<section id="accessing-a-dbt-project">
<h2>Accessing a <em>dbt</em> project<a class="headerlink" href="#accessing-a-dbt-project" title="Permalink to this heading"></a></h2>
<p><em>airflow-dbt-python</em> needs a way to access your <em>dbt</em> project to run. The requirements to grant this access will depend on how your Airflow environment is setup:</p>
<ol class="arabic simple">
<li><p>Using a <a class="reference external" href="https://airflow.apache.org/docs/apache-airflow/stable/executor/local.html">local executor</a> with a single-machine installation means we can rely on the local machine’s filesystem to store a <em>dbt</em> project. This also applies to <code class="docutils literal notranslate"><span class="pre">DebugExecutor</span></code> and <code class="docutils literal notranslate"><span class="pre">SequentialExecutor</span></code>, but these executors are generally only used for debugging/development so we will ignore them. If you are running a setup like this, then simply ensure your <em>dbt</em> project and <em>profiles.yml</em> exist somewhere in the <code class="docutils literal notranslate"><span class="pre">LocalExecutor</span></code>’s file system.</p></li>
<li><p>Once your setup has evolved to a multi-machine/cloud installation with any remote executor, we must rely on a remote storage for <em>dbt</em> files. Currently, supported remote storages include AWS S3 and git remote repositories although more are in plans to be added. In this setup, your <em>dbt</em> project will need to be uploaded to a remote storage that Airflow can access. <em>airflow-dbt-python</em> can utilize Airflow connections to access these storages.</p></li>
</ol>
<section id="single-machine-installation">
<h3>Single-machine installation<a class="headerlink" href="#single-machine-installation" title="Permalink to this heading"></a></h3>
<p>As we can rely on the local machine’s filesystem, simply copy or move your <em>dbt</em> project <em>profiles.yml</em> to a path in the instance executing Airflow.</p>
<p>Files may be laid out as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>.
|-- ~/.dbt/
|   `-- profiles.yml
`-- /path/to/project/
    |-- dbt_project.yml
    |-- models/
    |   |-- model1.sql
    |   `-- model2.sql
    |-- seeds/
    |   |-- seed1.csv
    |   `-- seed2.csv
    |-- macros/
    |   |-- macro1.csv
    |   `-- macro2.csv
    `-- tests/
        |-- test1.sql
        `-- test2.sql
</pre></div>
</div>
<p>Then we can simply set <code class="docutils literal notranslate"><span class="pre">project_dir</span></code> and <code class="docutils literal notranslate"><span class="pre">profiles_dir</span></code> to <code class="docutils literal notranslate"><span class="pre">&quot;/path/to/project/&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">&quot;~/.dbt/&quot;</span></code> respectively:</p>
<div class="literal-block-wrapper docutils container" id="id4">
<div class="code-block-caption"><span class="caption-text">example_local_1_dag.py</span><a class="headerlink" href="#id4" title="Permalink to this code"></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="kn">import</span> <span class="nn">datetime</span> <span class="k">as</span> <span class="nn">dt</span>
<span class="linenos"> 2</span>
<span class="linenos"> 3</span><span class="kn">import</span> <span class="nn">pendulum</span>
<span class="linenos"> 4</span><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span>
<span class="linenos"> 5</span><span class="kn">from</span> <span class="nn">airflow_dbt_python.operators.dbt</span> <span class="kn">import</span> <span class="n">DbtRunOperator</span>
<span class="linenos"> 6</span>
<span class="linenos"> 7</span><span class="k">with</span> <span class="n">DAG</span><span class="p">(</span>
<span class="linenos"> 8</span>    <span class="n">dag_id</span><span class="o">=</span><span class="s2">&quot;example_local_1&quot;</span><span class="p">,</span>
<span class="linenos"> 9</span>    <span class="n">schedule_interval</span><span class="o">=</span><span class="s2">&quot;0 0 * * *&quot;</span><span class="p">,</span>
<span class="linenos">10</span>    <span class="n">start_date</span><span class="o">=</span><span class="n">pendulum</span><span class="o">.</span><span class="n">today</span><span class="p">(</span><span class="s2">&quot;UTC&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">days</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
<span class="linenos">11</span>    <span class="n">catchup</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="linenos">12</span>    <span class="n">dagrun_timeout</span><span class="o">=</span><span class="n">dt</span><span class="o">.</span><span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">60</span><span class="p">),</span>
<span class="linenos">13</span><span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>
<span class="linenos">14</span>    <span class="n">dbt_run</span> <span class="o">=</span> <span class="n">DbtRunOperator</span><span class="p">(</span>
<span class="linenos">15</span>        <span class="n">task_id</span><span class="o">=</span><span class="s2">&quot;dbt_run_daily&quot;</span><span class="p">,</span>
<span class="linenos">16</span>        <span class="n">project_dir</span><span class="o">=</span><span class="s2">&quot;/path/to/project&quot;</span><span class="p">,</span>
<span class="linenos">17</span>        <span class="n">profiles_dir</span><span class="o">=</span><span class="s2">&quot;~/.dbt/&quot;</span><span class="p">,</span>
<span class="linenos">18</span>        <span class="n">select</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;+tag:daily&quot;</span><span class="p">],</span>
<span class="linenos">19</span>        <span class="n">exclude</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;tag:deprecated&quot;</span><span class="p">],</span>
<span class="linenos">20</span>        <span class="n">target</span><span class="o">=</span><span class="s2">&quot;production&quot;</span><span class="p">,</span>
<span class="linenos">21</span>        <span class="n">profile</span><span class="o">=</span><span class="s2">&quot;my-project&quot;</span><span class="p">,</span>
<span class="linenos">22</span>   <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Setting <code class="docutils literal notranslate"><span class="pre">profiles_dir</span></code> to <code class="docutils literal notranslate"><span class="pre">&quot;~/.dbt/&quot;</span></code> can be omitted as this is the default value.</p>
</div>
<p>If we have multiple operators, we can also utilize default arguments and include other parameters like the profile and target to use:</p>
<div class="literal-block-wrapper docutils container" id="id5">
<div class="code-block-caption"><span class="caption-text">example_local_2_dag.py</span><a class="headerlink" href="#id5" title="Permalink to this code"></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="kn">import</span> <span class="nn">datetime</span> <span class="k">as</span> <span class="nn">dt</span>
<span class="linenos"> 2</span>
<span class="linenos"> 3</span><span class="kn">import</span> <span class="nn">pendulum</span>
<span class="linenos"> 4</span><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span>
<span class="linenos"> 5</span><span class="kn">from</span> <span class="nn">airflow_dbt_python.operators.dbt</span> <span class="kn">import</span> <span class="n">DbtRunOperator</span><span class="p">,</span> <span class="n">DbtSeedOperator</span>
<span class="linenos"> 6</span>
<span class="linenos"> 7</span><span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
<span class="linenos"> 8</span>   <span class="s2">&quot;project_dir&quot;</span><span class="p">:</span> <span class="s2">&quot;/path/to/project/&quot;</span><span class="p">,</span>
<span class="linenos"> 9</span>   <span class="s2">&quot;profiles_dir&quot;</span><span class="p">:</span> <span class="s2">&quot;~/.dbt/&quot;</span><span class="p">,</span>
<span class="linenos">10</span>   <span class="s2">&quot;target&quot;</span><span class="p">:</span> <span class="s2">&quot;production&quot;</span><span class="p">,</span>
<span class="linenos">11</span>   <span class="s2">&quot;profile&quot;</span><span class="p">:</span> <span class="s2">&quot;my-project&quot;</span><span class="p">,</span>
<span class="linenos">12</span><span class="p">}</span>
<span class="linenos">13</span>
<span class="linenos">14</span><span class="k">with</span> <span class="n">DAG</span><span class="p">(</span>
<span class="linenos">15</span>    <span class="n">dag_id</span><span class="o">=</span><span class="s2">&quot;example_local_2&quot;</span><span class="p">,</span>
<span class="linenos">16</span>    <span class="n">schedule_interval</span><span class="o">=</span><span class="s2">&quot;0 0 * * *&quot;</span><span class="p">,</span>
<span class="linenos">17</span>    <span class="n">start_date</span><span class="o">=</span><span class="n">pendulum</span><span class="o">.</span><span class="n">today</span><span class="p">(</span><span class="s2">&quot;UTC&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">days</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
<span class="linenos">18</span>    <span class="n">catchup</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="linenos">19</span>    <span class="n">dagrun_timeout</span><span class="o">=</span><span class="n">dt</span><span class="o">.</span><span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">60</span><span class="p">),</span>
<span class="linenos">20</span>    <span class="n">default_args</span><span class="o">=</span><span class="n">default_args</span><span class="p">,</span>
<span class="linenos">21</span><span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>
<span class="linenos">22</span>    <span class="n">dbt_seed</span> <span class="o">=</span> <span class="n">DbtSeedOperator</span><span class="p">(</span>
<span class="linenos">23</span>        <span class="n">task_id</span><span class="o">=</span><span class="s2">&quot;dbt_seed&quot;</span><span class="p">,</span>
<span class="linenos">24</span>    <span class="p">)</span>
<span class="linenos">25</span>
<span class="linenos">26</span>    <span class="n">dbt_run</span> <span class="o">=</span> <span class="n">DbtRunOperator</span><span class="p">(</span>
<span class="linenos">27</span>        <span class="n">task_id</span><span class="o">=</span><span class="s2">&quot;dbt_run_daily&quot;</span><span class="p">,</span>
<span class="linenos">28</span>        <span class="n">select</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;+tag:daily&quot;</span><span class="p">],</span>
<span class="linenos">29</span>        <span class="n">exclude</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;tag:deprecated&quot;</span><span class="p">],</span>
<span class="linenos">30</span>    <span class="p">)</span>
<span class="linenos">31</span>
<span class="linenos">32</span>    <span class="n">dbt_seed</span> <span class="o">&gt;&gt;</span> <span class="n">dbt_run</span>
</pre></div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><em>dbt</em> supports configuration via environment variables, which may also be used. Additionally, <code class="docutils literal notranslate"><span class="pre">profile</span></code> and <code class="docutils literal notranslate"><span class="pre">target</span></code> may be omitted if already specified in <code class="docutils literal notranslate"><span class="pre">dbt_project.yml</span></code> and <code class="docutils literal notranslate"><span class="pre">profiles.yml</span></code> respectively.</p>
</div>
</section>
<section id="multi-machine-cloud-installation">
<h3>Multi-machine/cloud installation<a class="headerlink" href="#multi-machine-cloud-installation" title="Permalink to this heading"></a></h3>
<p>When Airflow is installed is running on a multi- machine or cloud installation, each individual worker does not have does not have access to a common filesystem that we can reliably use to store <em>dbt</em> project files (at least, assuming any deployment with more than one worker). This includes both self-hosted deployments as well as managed Airflow deployments like AWS MWAA or Astronomer.</p>
<p>For these deployments we must rely on a <em>dbt</em> remote to download and, eventually, upload all required <em>dbt</em> files. The remote <em>dbt</em> URL may be used in place of a local <code class="docutils literal notranslate"><span class="pre">project_dir</span></code> or <code class="docutils literal notranslate"><span class="pre">profiles_dir</span></code> to have <em>airflow-dbt-python</em> download the <em>dbt</em> files in the remote into a temporary directory for execution.</p>
<p>Interactions with storages are supported by subclasses of <code class="docutils literal notranslate"><span class="pre">DbtRemoteHook</span></code>. Read the documentation <a class="reference internal" href="how_does_it_work.html#dbt-remote-hooks"><span class="std std-ref">dbt remote hooks</span></a> to learn more about these hooks.</p>
<p>As an example, let’s upload our <em>dbt</em> project to an AWS S3 bucket. The files may end up structured in the bucket as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>s3://my-bucket/
.
|-- profiles/
|   `-- profiles.yml
`-- project/
    |-- dbt_project.yml
    |-- models/
    |   |-- model1.sql
    |   `-- model2.sql
    |-- seeds/
    |   |-- seed1.csv
    |   `-- seed2.csv
    |-- macros/
    |   |-- macro1.csv
    |   `-- macro2.csv
    `-- tests/
        |-- test1.sql
        `-- test2.sql
</pre></div>
</div>
<p>Then, we can alter the previous example DAG to set <code class="docutils literal notranslate"><span class="pre">project_dir</span></code> and <code class="docutils literal notranslate"><span class="pre">profiles_dir</span></code> to <code class="docutils literal notranslate"><span class="pre">&quot;s3://my-bucket/project/&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">&quot;s3://my-bucket/profiles/&quot;</span></code> respectively:</p>
<div class="literal-block-wrapper docutils container" id="id6">
<div class="code-block-caption"><span class="caption-text">example_s3_remote_1_dag.py</span><a class="headerlink" href="#id6" title="Permalink to this code"></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="kn">import</span> <span class="nn">datetime</span> <span class="k">as</span> <span class="nn">dt</span>
<span class="linenos"> 2</span>
<span class="linenos"> 3</span><span class="kn">import</span> <span class="nn">pendulum</span>
<span class="linenos"> 4</span><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span>
<span class="linenos"> 5</span><span class="kn">from</span> <span class="nn">airflow_dbt_python.operators.dbt</span> <span class="kn">import</span> <span class="n">DbtRunOperator</span>
<span class="linenos"> 6</span>
<span class="linenos"> 7</span><span class="k">with</span> <span class="n">DAG</span><span class="p">(</span>
<span class="linenos"> 8</span>    <span class="n">dag_id</span><span class="o">=</span><span class="s2">&quot;example_s3_remote_1&quot;</span><span class="p">,</span>
<span class="linenos"> 9</span>    <span class="n">schedule_interval</span><span class="o">=</span><span class="s2">&quot;0 0 * * *&quot;</span><span class="p">,</span>
<span class="linenos">10</span>    <span class="n">start_date</span><span class="o">=</span><span class="n">pendulum</span><span class="o">.</span><span class="n">today</span><span class="p">(</span><span class="s2">&quot;UTC&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">days</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
<span class="linenos">11</span>    <span class="n">catchup</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="linenos">12</span>    <span class="n">dagrun_timeout</span><span class="o">=</span><span class="n">dt</span><span class="o">.</span><span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">60</span><span class="p">),</span>
<span class="linenos">13</span><span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>
<span class="linenos">14</span>    <span class="n">dbt_run</span> <span class="o">=</span> <span class="n">DbtRunOperator</span><span class="p">(</span>
<span class="linenos">15</span>        <span class="n">task_id</span><span class="o">=</span><span class="s2">&quot;dbt_run_daily&quot;</span><span class="p">,</span>
<span class="hll"><span class="linenos">16</span>        <span class="n">project_dir</span><span class="o">=</span><span class="s2">&quot;s3://my-bucket/project/&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="linenos">17</span>        <span class="n">profiles_dir</span><span class="o">=</span><span class="s2">&quot;s3://my-bucket/profiles/&quot;</span><span class="p">,</span>
</span><span class="linenos">18</span>        <span class="n">select</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;+tag:daily&quot;</span><span class="p">],</span>
<span class="linenos">19</span>        <span class="n">exclude</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;tag:deprecated&quot;</span><span class="p">],</span>
<span class="linenos">20</span>        <span class="n">target</span><span class="o">=</span><span class="s2">&quot;production&quot;</span><span class="p">,</span>
<span class="linenos">21</span>        <span class="n">profile</span><span class="o">=</span><span class="s2">&quot;my-project&quot;</span><span class="p">,</span>
<span class="linenos">22</span>   <span class="p">)</span>
</pre></div>
</div>
</div>
<p><em>airflow-dbt-python</em> uses the URL scheme (in this example, <code class="docutils literal notranslate"><span class="pre">&quot;s3&quot;</span></code>) to figure out the type of remote, and the corresponding <code class="docutils literal notranslate"><span class="pre">DbtRemoteHook</span></code> to download all required files. An exception would be raised if the scheme does not point to a supported remote.</p>
<p><em>airflow-dbt-python</em> takes care of adjusting any path-like arguments so that they are pointing to files in a local temporary directory once all the <em>dbt</em> files are download from the remote storage.</p>
<p>Let’s do another example where we upload our <em>dbt</em> project to a GitHub repository. For this example, let’s use dbt-labs’ own <a class="reference external" href="https://github.com/dbt-labs/jaffle_shop">jaffle_shop</a>.</p>
<p>The DAG looks the same as the AWS S3 example, except that now we use the GitHub repository’s SSH URL as the <code class="docutils literal notranslate"><span class="pre">project_dir</span></code> argument:</p>
<div class="literal-block-wrapper docutils container" id="id7">
<div class="code-block-caption"><span class="caption-text">example_git_remote_1_dag.py</span><a class="headerlink" href="#id7" title="Permalink to this code"></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="kn">import</span> <span class="nn">datetime</span> <span class="k">as</span> <span class="nn">dt</span>
<span class="linenos"> 2</span>
<span class="linenos"> 3</span><span class="kn">import</span> <span class="nn">pendulum</span>
<span class="linenos"> 4</span><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span>
<span class="linenos"> 5</span><span class="kn">from</span> <span class="nn">airflow_dbt_python.operators.dbt</span> <span class="kn">import</span> <span class="n">DbtRunOperator</span>
<span class="linenos"> 6</span>
<span class="linenos"> 7</span><span class="k">with</span> <span class="n">DAG</span><span class="p">(</span>
<span class="linenos"> 8</span>    <span class="n">dag_id</span><span class="o">=</span><span class="s2">&quot;example_git_remote_1&quot;</span><span class="p">,</span>
<span class="linenos"> 9</span>    <span class="n">schedule_interval</span><span class="o">=</span><span class="s2">&quot;0 0 * * *&quot;</span><span class="p">,</span>
<span class="linenos">10</span>    <span class="n">start_date</span><span class="o">=</span><span class="n">pendulum</span><span class="o">.</span><span class="n">today</span><span class="p">(</span><span class="s2">&quot;UTC&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">days</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
<span class="linenos">11</span>    <span class="n">catchup</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="linenos">12</span>    <span class="n">dagrun_timeout</span><span class="o">=</span><span class="n">dt</span><span class="o">.</span><span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">60</span><span class="p">),</span>
<span class="linenos">13</span><span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>
<span class="linenos">14</span>    <span class="n">dbt_run</span> <span class="o">=</span> <span class="n">DbtRunOperator</span><span class="p">(</span>
<span class="linenos">15</span>        <span class="n">task_id</span><span class="o">=</span><span class="s2">&quot;dbt_run_daily&quot;</span><span class="p">,</span>
<span class="hll"><span class="linenos">16</span>        <span class="n">project_dir</span><span class="o">=</span><span class="s2">&quot;git+ssh://github.com:dbt-labs/jaffle_shop&quot;</span><span class="p">,</span>
</span><span class="linenos">17</span>        <span class="n">select</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;+tag:daily&quot;</span><span class="p">],</span>
<span class="linenos">18</span>        <span class="n">exclude</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;tag:deprecated&quot;</span><span class="p">],</span>
<span class="linenos">19</span>        <span class="n">target</span><span class="o">=</span><span class="s2">&quot;my_warehouse_connection&quot;</span><span class="p">,</span>
<span class="linenos">20</span>        <span class="n">profile</span><span class="o">=</span><span class="s2">&quot;my-project&quot;</span><span class="p">,</span>
<span class="linenos">21</span>   <span class="p">)</span>
</pre></div>
</div>
</div>
<p><em>airflow-dbt-python</em> can determine this URL requires a <code class="docutils literal notranslate"><span class="pre">DbtGitRemoteHook</span></code> by looking at the URL’s scheme (<code class="docutils literal notranslate"><span class="pre">&quot;git+ssh&quot;</span></code>). As we are passing an SSH URL, <code class="docutils literal notranslate"><span class="pre">DbtGitRemoteHook</span></code> can utilize an Airflow <a class="reference external" href="https://airflow.apache.org/docs/apache-airflow-providers-ssh/stable/connections/ssh.html">SSH Connection</a> as it subclasses Airflow’s <code class="docutils literal notranslate"><span class="pre">SSHHook</span></code>. This connection type allows us to setup the necessary SSH keys to access GitHub. Of course, as this is a public repository, we could have just used an HTTP URL, but for private repositories an SSH key may be required.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><em>airflow-dbt-python</em> can utilize Airflow Connections to fetch connection details for <em>dbt</em> remotes as well as for <em>dbt</em> targets (e.g. for your data warehouse). The <code class="docutils literal notranslate"><span class="pre">project_conn_id</span></code> and <code class="docutils literal notranslate"><span class="pre">profiles_conn_id</span></code> arguments that all <em>dbt</em> operators have refer to Airflow Connections to used to fetch <em>dbt</em> projects and <em>profiles.yml</em> respectively, whereas the <code class="docutils literal notranslate"><span class="pre">target</span></code> argument can point to an Airflow Connection used to setup <em>dbt</em> to access your data warehouse.</p>
</div>
<p>Notice we are omitting the <code class="docutils literal notranslate"><span class="pre">profiles_dir</span></code> argument as the jaffle_shop repo doesn’t include a <code class="docutils literal notranslate"><span class="pre">profiles.yml</span></code> file we can use. When we omit <code class="docutils literal notranslate"><span class="pre">profiles_dir</span></code>, <em>airflow-dbt-python</em> will attempt to find <em>dbt</em> connection details in one of two places:</p>
<ol class="arabic simple">
<li><p>First, it will check if the <code class="docutils literal notranslate"><span class="pre">project_dir</span></code> URL already includes a <code class="docutils literal notranslate"><span class="pre">profiles.yml</span></code>. If so, we can use it.</p></li>
<li><p>If it’s not included, <em>airflow-dbt-python</em> will try to find an Airflow Connection using the <code class="docutils literal notranslate"><span class="pre">target</span></code> argument.</p></li>
</ol>
<p>Airflow Connections are generally created in the UI, but for illustration purposes we can create one also in our DAG with:</p>
<div class="literal-block-wrapper docutils container" id="id8">
<div class="code-block-caption"><span class="caption-text">example_git_remote_1_dag.py</span><a class="headerlink" href="#id8" title="Permalink to this code"></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span><span class="p">,</span> <span class="n">settings</span>
<span class="linenos"> 2</span><span class="kn">from</span> <span class="nn">airflow.models.connection</span> <span class="kn">import</span> <span class="n">Connection</span>
<span class="linenos"> 3</span>
<span class="linenos"> 4</span><span class="n">session</span> <span class="o">=</span> <span class="n">settings</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="linenos"> 5</span><span class="n">my_conn</span> <span class="o">=</span> <span class="n">Connection</span><span class="p">(</span>
<span class="linenos"> 6</span>    <span class="n">conn_id</span><span class="o">=</span><span class="s2">&quot;my_db_connection&quot;</span><span class="p">,</span>
<span class="linenos"> 7</span>    <span class="n">conn_type</span><span class="o">=</span><span class="s2">&quot;postgres&quot;</span><span class="p">,</span>
<span class="linenos"> 8</span>    <span class="n">description</span><span class="o">=</span><span class="s2">&quot;A test postgres connection&quot;</span><span class="p">,</span>
<span class="linenos"> 9</span>    <span class="n">host</span><span class="o">=</span><span class="s2">&quot;localhost&quot;</span><span class="p">,</span>
<span class="linenos">10</span>    <span class="n">login</span><span class="o">=</span><span class="s2">&quot;username&quot;</span><span class="p">,</span>
<span class="linenos">11</span>    <span class="n">port</span><span class="o">=</span><span class="mi">5432</span><span class="p">,</span>
<span class="linenos">12</span>    <span class="n">schema</span><span class="o">=</span><span class="s2">&quot;my_dbt_schema&quot;</span><span class="p">,</span>
<span class="linenos">13</span>    <span class="n">password</span><span class="o">=</span><span class="s2">&quot;password&quot;</span><span class="p">,</span>
<span class="linenos">14</span>    <span class="c1"># Other dbt parameters can be added as extras</span>
<span class="linenos">15</span>    <span class="n">extra</span><span class="o">=</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">threads</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">sslmode</span><span class="o">=</span><span class="s2">&quot;require&quot;</span><span class="p">)),</span>
<span class="linenos">16</span><span class="p">)</span>
<span class="linenos">17</span>
<span class="linenos">18</span><span class="n">session</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">my_conn</span><span class="p">)</span>
<span class="linenos">19</span><span class="n">session</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
</pre></div>
</div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="introduction.html" class="btn btn-neutral float-left" title="Introduction" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="example_dags.html" class="btn btn-neutral float-right" title="Example DAGs" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Copyright 2021 Tomás Farías Santana.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>